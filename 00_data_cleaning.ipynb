{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a82fad1-5201-4194-9fc6-f039109ef3bd",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f6f6a-01f7-4fce-acba-8ba18f536bf5",
   "metadata": {},
   "source": [
    "We are going to do cleaning and exploratory data analysis on the following data set: https://www.kaggle.com/datasets/wordsforthewise/lending-club.\n",
    "\n",
    "This data consists of loan data from the lending club, and we want to set up as a **binary** classification problem where we try to predict whether a loan defaulted or not.\n",
    "\n",
    "Here are some hints and questions to consider:\n",
    "   \n",
    "1. The column of `loan_status` contains the label information that we need.  What are the different values? How can we turn this into a binary classification problem?\n",
    "\n",
    "    a. Change the label to `True` if the loan defaulted and `False` if the loan did not default.  Use the `pandas.get_dummies()` function for this.\n",
    "\n",
    "\n",
    "1. Check for `NaN`s in the data set.  What do you notice?  How would you handle this?\n",
    "\n",
    "1. Identify three categorical to keep, and three categorical features that you would for drop - justify your answer.\n",
    "\n",
    "    a. How are you going to identify which features are categorical?\n",
    "\n",
    "    b. Once you've identified, which features are categorical, how will you determine if a feature is worth including in the model? The key to my approach is testing $Pr(Y=1|X)$, where $X$ is some feature.\n",
    "\n",
    "    c. `debt_settlement_flag` looks suspicious.  Why?\n",
    "\n",
    "    d. `earliest_cr_line` might be interesting, but it needs to be converted into a numerical format.\n",
    "\n",
    "    e. `emp_length` might be an interesting numerical feature, but it's in a text format, convert it to a numerical format using the `Series.replace()` method.\n",
    "\n",
    "    f. What are your thoughts on `emp_title`?  Should it be kept?\n",
    "\n",
    "    g. `home_ownership` looks interesting but check the `.value_counts()`.  What do you notice?  How would you deal with this?\n",
    "\n",
    "1. Next, let's move on to the numerical variables.  Choose a few that you think are interesting and determine whether we should keep them in.  Select 5 numerical features to keep, and identify 3 that shouldn't be kept - justify your answer.\n",
    "\n",
    "    a. Once again, the approach I took was to model $Pr(Y=1|X)$.  However, at times you have to be a little more clever and use some *bucketing* of the data to get interpretable results.\n",
    "\n",
    "    b. `recoveries` looks suspicious. Why? The `pd.cut()` method might be useful in analyzing this.\n",
    "\n",
    "1. Using the 5 numerical features you identified in the question above, fit a `LogisticRegression`.\n",
    "\n",
    "    a. Use `cross_val_score()` to estimate your out-of-sample accuracy.  How does your model compare to the degenerate predictor of always guessing `False`?\n",
    "\n",
    "    b. Depending on the features you choose, you will likely run into an error when trying to do this.  What is it and how will you deal with it?\n",
    "\n",
    "    c. Fit your model to the entire data set, and check how often your model is predicting `True` (in-sample).  Compare this to the prevalence of `True` in the training labels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
